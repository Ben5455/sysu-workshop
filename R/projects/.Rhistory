333 * 5666
1 + 1
333 * 5666
print("hehe")
print("hehe")
1 + 1
333 * 5666
print("hehe")
1 + 1
333 * 5666
print("hehe")
1 + 1
333 * 5666
# print("hehe")
1 + 1
333 * 5666
print("hehe")
# 1 + 1
# 333 * 5666
# print("hehe")
1+1
1:1000
1:1000
max(1,3,5)
q()
help(max)
min(5:1, pi) #-> one number
pi
example(max)
x = 1
x = 1
x <- 1
x <- 3
X <- 44
x <- 3
y <- 4
z <- sqrt(x^2+y^2)
z
x <- "geography"
print(x)
Y <- geography
ls()
ls.str()
c(1,3,5,7)
c(1:100)
c("a","b","c")
c(TRUE,FALSE,TRUE)
true
v1 <- c(1,3,5)
v2 <- c(2,4,6)
v3 <- c(v1,v2)
v3
mode(v1)
num <- 1:10
num
mean(num)
median(num)
sd(num)
var(num)
num <- 1:=10010
num
mean(num)
median(num)
sd(num)
var(num)
num <- 1:10010
num
mean(num)
median(num)
sd(num)
var(num)
library("datasets", lib.loc="C:/Program Files/R/R-3.4.0/library")
df <- cars
View(df)
str(df)
summary(df)
View(df)
fix(df)
fix(df)
plot(df$speed,df$dist)
df$speed
df$dist
df[1,1]
df[10,2]
df[5,]
df[,2]
df[c(1,3,5,7),]
seq(from = 1, to = 999,by = 2)
seq(1,999,2)
seq(1,999,5)
df[seq(1,50,2),]
df[seq(1,50,3),]
seq(1,1000,2)
seq(1,1000,length.out = 300)
library("leaflet", lib.loc="~/R/win-library/3.4")
detach("package:leaflet", unload=TRUE)
library(leaflet)
library(leaflet)
pal <- colorQuantile("YlOrRd", NULL, n = 8)
leaflet(orstationc) %>%
addTiles() %>%
addCircleMarkers(color = ~pal(tann))
library(leaflet)
pal <- colorQuantile("YlOrRd", NULL, n = 8)
leaflet(pal) %>%
addTiles() %>%
addCircleMarkers(color = ~pal(tann))
library(networkD3)
data(MisLinks, MisNodes)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
Group = "group", opacity = 0.4)
install.packages("networkD3")
library(networkD3)
data(MisLinks, MisNodes)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
Group = "group", opacity = 0.4)
library(ggplot2)
library(plotly)
p <- ggplot(data = diamonds, aes(x = cut, fill = clarity)) +
geom_bar(position = "dodge")
ggplotly(p)
plot(cars)
plot(cars)
plot(cars,type = "b")
v1 <- c(1,3,5)
v2 <- c(2,4,6)
v3 <- c(v1,v2)
v3
library(networkD3)
data(MisLinks, MisNodes)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
Group = "group", opacity = 0.4)
library(ggplot2)
library(plotly)
p <- ggplot(data = diamonds, aes(x = cut, fill = clarity)) +
geom_bar(position = "dodge")
ggplotly(p)
library(ggplot2)
library(plotly)
p <- ggplot(data = diamonds, aes(x = cut, fill = clarity)) +
geom_bar(position = "dodge")
ggplotly(p)
plot(cars,type = "b")
v1 <- c(1,3,5)
v2 <- c(2,4,6)
v3 <- c(v1,v2)
v3
library(networkD3)
data(MisLinks, MisNodes)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
Group = "group", opacity = 0.4)
library(ggplot2)
library(plotly)
p <- ggplot(data = diamonds, aes(x = cut, fill = clarity)) +
geom_bar(position = "dodge")
ggplotly(p)
df <- read.csv("students.csv")
df <- read.csv("students.csv")
View(df)
View(df)
str(df)
df$Last.Name
df$Last.Name <- as.character(df$Last.Name)
df$First.Name <- as.character(df$First.Name)
str(df)
df <- read.csv("students.csv",stringsAsFactors = FALSE)
str(df)
install.packages("fBasics")
library(fBasics)
df <- read.csv("students.csv")
SAT <- df$SAT
basicStats(SAT)
summary(SAT)
hist(SAT)
hist(df$SAT,main = "Histogram of SAT Score",xlab = "SAT Score",ylab = "Frequency",col="green")
hist(df$SAT,main = "Histogram of SAT Score",xlab = "SAT Score",ylab = "Frequency",col="BLUE")
df <- read.csv("students.csv")
SAT.mean <- tapply(df$SAT, df$Gender, mean)
print(SAT.mean)
SAT.median <- tapply(df$SAT, df$Gender, median)
print(SAT.median)
SAT.sd <- tapply(df$SAT, df$Gender, sd)
print(SAT.sd)
round(cbind(SAT.mean,SAT.median,SAT.sd,SAT.max),digits = 1)
t1 <- round(cbind(SAT.mean,SAT.median,SAT.sd,SAT.max),digits = 1)
write.csv(df,file = "newstudent.csv")
df$NEWSAT <- df$SAT / 2
View(df)
write.csv(df,file = "newstudent.csv")
write.csv(df,file = "newstudent.csv")
x <- rnorm(20)
y <- rnorm(20)
cor(x,y)
cor.test(x,y)
x <- rnorm(20)
y <- rnorm(20)
cor(x,y)
cor.test(x,y)
cor.test(x,y,method="spearman")
df <- read.csv("ExamAnxiety.csv",header = TRUE)
df <- read.csv("data/ExamAnxiety.csv",header = TRUE)
plot(df)
x <- seq(from=0,to = 1,by = 0.01)
y <- x + rnorm(100)
plot(x,y)
x <- seq(from=0,to = 1,by = 0.01)
y <- x + rnorm(100)
x <- seq(from=0,to = 1,length.out = 100)
y <- x + rnorm(100)
plot(x,y)
df <- mtcars
cor(df)
plot(df)
plot(df$hp,df$qsec)
abline(lm(df$qsec ~ df$hp))
plot(df)
mpg <- df$mpg
wt <- df$wt
plot(wt, mpg)
n <- nrow(df)
var(mpg)
sum((mpg - mean(mpg))^2) / (n-1)
cor.test(examData$Exam, examData$Anxiety, method = "pearson")
examData <- read.csv("ExamAnxiety.csv",header = TRUE)
examData <- read.csv("data/ExamAnxiety.csv",header = TRUE)
cor(examData, use = "complete.obs", method = "pearson")
cor(examData$Exam, examData$Anxiety, use = "complete.obs", method = "pearson")
cor.test(examData$Exam, examData$Anxiety, method = "pearson")
url <- "data/ExamAnxiety.csv"
examData <- read.csv(url,header = TRUE)
library(knitr)
## display first 10 rows
kable(head(examData,n = 10))
plot(examData$Anxiety,examData$Exam,xlab = "Anxiety",ylab = "Exam Score")
#abline(lm(examData$Exam~examData$Anxiety))
cor(examData,use = "complete.obs",method = "pearson")
cor.test(examData$Exam,examData$Anxiety,method = "pearson")
cor.test(examData$Exam, examData$Anxiety, alternative = "less", method = "pearson")
result <- cor.test(examData$Exam, examData$Anxiety, alternative = "less", method = "pearson")
str(result)
r <- result$estimate
n <- nrow(examData)
t <- r*sqrt(n-2)/sqrt(1-r^2)
t
pt(t,df = n-2)
curve(dt(x,df = n-2),from = -6,to = 6)
t.critical <- qt(0.025,df = n-2)
t.critical
points(t.critical,dt(t.critical,df = n-2),pch=16,col="red")
points(t,dt(t,df = n-2),pch=16,col="blue")
url <- "data/ExamAnxiety.csv"
examData <- read.csv(url,header = TRUE)
library(knitr)
## display first 10 rows
kable(head(examData,n = 10))
plot(examData$Anxiety,examData$Exam,xlab = "Anxiety",ylab = "Exam Score")
#abline(lm(examData$Exam~examData$Anxiety))
cor(examData,use = "complete.obs",method = "pearson")
cor.test(examData$Exam,examData$Anxiety,method = "pearson")
cor.test(examData$Exam, examData$Anxiety, alternative = "less", method = "pearson")
result <- cor.test(examData$Exam, examData$Anxiety, alternative = "less", method = "pearson")
str(result)
r <- result$estimate
n <- nrow(examData)
t <- r*sqrt(n-2)/sqrt(1-r^2)
t
pt(t,df = n-2)
curve(dt(x,df = n-2),from = -6,to = 6)
t.critical <- qt(0.025,df = n-2)
t.critical
points(t.critical,dt(t.critical,df = n-2),pch=16,col="red")
points(t,dt(t,df = n-2),pch=16,col="blue")
n <- c(10,15,20,30,50,100,250,500,1000)
r <- round(2/sqrt(n),3)
df <- data.frame(n,r)
names(df) <- c("Sample size", "Minimum absolute value of r needed to attain significance")
library(knitr)
kable(df)
url <- "data/TheBiggestLiar.csv"
liarData <- read.csv(url,header = TRUE)
library(knitr)
## display first ten rows
kable(head(liarData,n = 10))
plot(liarData$Creativity,liarData$Position)
cor(liarData$Position, liarData$Creativity, method = "spearman")
cor.test(liarData$Position, liarData$Creativity, alternative = "less", method = "spearman")
df <- read.csv("data/AlbumSales1.csv",header = TRUE)
plot(df)
m <- lm(df$sales ~ df$adverts)
m
View(df)
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
attributes(m)
plot(m)
m <- lm(df$sales ~ df$adverts)
m
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
attributes(m)
plot(m)
df <- cars
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(y~x)
summary(m)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
lm(y~x,data = dfrm)
url <- "data/AlbumSales1.csv"
df <- read.csv(url,header = TRUE)
library(knitr)
kable(head(df,n = 10))
plot(df)
m <- lm(df$sales ~ df$adverts)
m
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
attributes(m)
df <- cars
library(knitr)
kable(head(df,n = 10))
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(y~x)
m
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
result <- cor.test(x,y,method = "pearson")
result
r <- result$estimate
r2 <- r^2
round(r2,4)
p=1
n=nrow(df)
adjusted.r2 <- r2-(1-r2)*p/(n-p-1)
round(adjusted.r2,4)
df <- cars
m <- lm(dist~speed,data = df)
n <- nrow(df)
df$x <- sample(10:100,size = n)
df$y <- predict(m,newdata = data.frame(speed=df$x))
library(knitr)
kable(head(df,n = 10))
plot(df$x,df$y)
abline(m,col="red")
x <- c(65,35,30,44,80,77,32,39,44,77)
y <- c(120,68,35,60,100,91,44,71,89,113)
library(knitr)
kable(cbind(y,x))
n <- length(x)
mx <- mean(x)
my <- mean(y)
sx <- sd(x)
sy <- sd(y)
numerator <- sum((x-mx)*(y-my))
numerator
denominator <- sum((x-mx)^2)
denominator
slope <- numerator / denominator
slope
intercept <- my - slope * mx
intercept
m <- lm(y~x)
summary(m)
MSS <- sum((fitted(m) - my)^2)
MSS
RSS <- sum((y - fitted(m))^2)
RSS
TSS <- RSS + MSS
TSS
df1 <- 1
df2 <- n-2
df3 <- df1+df2
msq1 <- MSS / df1
msq2 <- RSS / df2
F.value <- msq1 / msq2
F.value
F.critical <- qf(0.95,df1 = 1,df2 = n-2)
F.critical
rsq <- MSS / TSS
rsq
if(F.value>F.critical){
print("We reject the null hypothesis")
} else {
print("We cannot reject the null hypothesis")
}
url <- "data/AlbumSales2.csv"
df <- read.csv(url,header = TRUE)
library(knitr)
kable(head(df,10))
m <- lm(sales ~ adverts + airplay + attract, data = df)
## m <- lm(sales ~ ., data = df)
summary(m)
anova(m)
coefficients(m)
coef(m)
a <- round(coef(m)[1],2)
b1 <- round(coef(m)[2],2)
b2 <- round(coef(m)[3],2)
b3 <- round(coef(m)[4],2)
set.seed(100)
race <- c(rep("Asian",50),rep("White",50),rep("Hispanic",50),rep("Black",50))
income <- c(rnorm(50,68636,10000),rnorm(50,57009),rnorm(50,39005,10000),rnorm(50,33321,10000))
df <- data.frame(income,race)
df <- df[sample(1:nrow(df)),]
library(knitr)
kable(head(df,15))
tapply(df$income, df$race, median)
m <- lm(income~race,data = df)
summary(m)
a <- round(coef(m)[1],0)
b1 <- round(coef(m)[2],0)
b2 <- round(coef(m)[3],0)
b3 <- round(coef(m)[4],0)
## income = 69451 - 34909*Black - 31444*Hispanic - 12442*White
summary(df$race)
levels(df$race)
contrasts(df$race) <- contr.treatment(4,base = 2)
df$race
m <- lm(income~race,data = df)
summary(m)
## income = 34541 + 34909*Asian + 3465*Hispanic + 22467*White
if(!require(rgdal)) install.packages("rgdal")
setwd("data/shp_global110")  # set working directory
getwd() # print working directory
## use readOGR(dsn, layer) to read shapefile
land <- readOGR(".", "110m_land")   # "." represents current working directory
admin <- readOGR(".", "110m_admin_0_countries")
plot(land)
class(land)
#str(land)
# access some information about this object
proj <- proj4string(land)	# get the projection / coordinate reference system
proj
bbox(land)	# bounding box
land@bbox
xy <- coordinates(land)	# coordinates
summary(xy)
points(xy, pch=16,col="red")	# These are only the centre coordinates of the polygons!
# access the attribute table of a vector dataset with @data
data.df <- land@data
library(knitr)
kable(head(data.df,10))
summary(data.df)
setwd("data/shp_global110")
getwd()
files <- list.files(pattern=".shp")
files	# filenames of the files to be read
world <- readOGR(".","110m_land")
plot(world,col="grey",border="blue",bg = "lightblue")
plot(admin,add=TRUE)
lakes <- readOGR(".","110m_lakes")
plot(lakes,add=TRUE,col = "blue")
ocean <- readOGR(".","110m_ocean")
plot(ocean,add=TRUE,col = "lightblue")
setwd("output")
getwd()
setwd("output")
getwd()
library(rgdal)
writeOGR(land,dsn = ".",layer = "land",driver="ESRI Shapefile",overwrite_layer = TRUE)
shp <- readOGR(dsn = ".", layer = "land")
plot(shp)
bbox(shp)
proj4string(shp)
xy <- coordinates(shp)
df <- shp@data
names(df)
names(xy)
slotNames(shp)
plot(shp)
points(xy, pch=16,col="red")
library(rgdal)
setwd("data/shp_global110")
folder <- getwd()
shp <- readOGR(dsn = folder,layer = "continent")
getwd()
library(rgdal)
setwd("data/shp_global110")
folder <- getwd()
shp <- readOGR(dsn = folder,layer = "continent")
library(rgdal)
setwd("data/shp_global110")
folder <- "data/shp_global110"
shp <- readOGR(dsn = folder,layer = "continent")
getwd()
library(rgdal)
setwd("data/shp_global110")
folder <- getwd()
shp <- readOGR(dsn = folder,layer = "continent")
plot(shp,col="grey")
plot(shp,lwd=2,add=TRUE)
df <- shp@data
library(knitr)
kable(head(df,10))
sel <- df$CONTINENT == "North America"
plot(shp[sel,])
