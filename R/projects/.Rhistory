cor.test(examData$Exam, examData$Anxiety, alternative = "less", method = "pearson")
result <- cor.test(examData$Exam, examData$Anxiety, alternative = "less", method = "pearson")
str(result)
r <- result$estimate
n <- nrow(examData)
t <- r*sqrt(n-2)/sqrt(1-r^2)
t
pt(t,df = n-2)
curve(dt(x,df = n-2),from = -6,to = 6)
t.critical <- qt(0.025,df = n-2)
t.critical
points(t.critical,dt(t.critical,df = n-2),pch=16,col="red")
points(t,dt(t,df = n-2),pch=16,col="blue")
n <- c(10,15,20,30,50,100,250,500,1000)
r <- round(2/sqrt(n),3)
df <- data.frame(n,r)
names(df) <- c("Sample size", "Minimum absolute value of r needed to attain significance")
library(knitr)
kable(df)
url <- "data/TheBiggestLiar.csv"
liarData <- read.csv(url,header = TRUE)
library(knitr)
## display first ten rows
kable(head(liarData,n = 10))
plot(liarData$Creativity,liarData$Position)
cor(liarData$Position, liarData$Creativity, method = "spearman")
cor.test(liarData$Position, liarData$Creativity, alternative = "less", method = "spearman")
df <- read.csv("data/AlbumSales1.csv",header = TRUE)
plot(df)
m <- lm(df$sales ~ df$adverts)
m
View(df)
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
attributes(m)
plot(m)
m <- lm(df$sales ~ df$adverts)
m
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
attributes(m)
plot(m)
df <- cars
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(y~x)
summary(m)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
lm(y~x,data = dfrm)
url <- "data/AlbumSales1.csv"
df <- read.csv(url,header = TRUE)
library(knitr)
kable(head(df,n = 10))
plot(df)
m <- lm(df$sales ~ df$adverts)
m
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
attributes(m)
df <- cars
library(knitr)
kable(head(df,n = 10))
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(y~x)
m
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
result <- cor.test(x,y,method = "pearson")
result
r <- result$estimate
r2 <- r^2
round(r2,4)
p=1
n=nrow(df)
adjusted.r2 <- r2-(1-r2)*p/(n-p-1)
round(adjusted.r2,4)
df <- cars
m <- lm(dist~speed,data = df)
n <- nrow(df)
df$x <- sample(10:100,size = n)
df$y <- predict(m,newdata = data.frame(speed=df$x))
library(knitr)
kable(head(df,n = 10))
plot(df$x,df$y)
abline(m,col="red")
x <- c(65,35,30,44,80,77,32,39,44,77)
y <- c(120,68,35,60,100,91,44,71,89,113)
library(knitr)
kable(cbind(y,x))
n <- length(x)
mx <- mean(x)
my <- mean(y)
sx <- sd(x)
sy <- sd(y)
numerator <- sum((x-mx)*(y-my))
numerator
denominator <- sum((x-mx)^2)
denominator
slope <- numerator / denominator
slope
intercept <- my - slope * mx
intercept
m <- lm(y~x)
summary(m)
MSS <- sum((fitted(m) - my)^2)
MSS
RSS <- sum((y - fitted(m))^2)
RSS
TSS <- RSS + MSS
TSS
df1 <- 1
df2 <- n-2
df3 <- df1+df2
msq1 <- MSS / df1
msq2 <- RSS / df2
F.value <- msq1 / msq2
F.value
F.critical <- qf(0.95,df1 = 1,df2 = n-2)
F.critical
rsq <- MSS / TSS
rsq
if(F.value>F.critical){
print("We reject the null hypothesis")
} else {
print("We cannot reject the null hypothesis")
}
url <- "data/AlbumSales2.csv"
df <- read.csv(url,header = TRUE)
library(knitr)
kable(head(df,10))
m <- lm(sales ~ adverts + airplay + attract, data = df)
## m <- lm(sales ~ ., data = df)
summary(m)
anova(m)
coefficients(m)
coef(m)
a <- round(coef(m)[1],2)
b1 <- round(coef(m)[2],2)
b2 <- round(coef(m)[3],2)
b3 <- round(coef(m)[4],2)
set.seed(100)
race <- c(rep("Asian",50),rep("White",50),rep("Hispanic",50),rep("Black",50))
income <- c(rnorm(50,68636,10000),rnorm(50,57009),rnorm(50,39005,10000),rnorm(50,33321,10000))
df <- data.frame(income,race)
df <- df[sample(1:nrow(df)),]
library(knitr)
kable(head(df,15))
tapply(df$income, df$race, median)
m <- lm(income~race,data = df)
summary(m)
a <- round(coef(m)[1],0)
b1 <- round(coef(m)[2],0)
b2 <- round(coef(m)[3],0)
b3 <- round(coef(m)[4],0)
## income = 69451 - 34909*Black - 31444*Hispanic - 12442*White
summary(df$race)
levels(df$race)
contrasts(df$race) <- contr.treatment(4,base = 2)
df$race
m <- lm(income~race,data = df)
summary(m)
## income = 34541 + 34909*Asian + 3465*Hispanic + 22467*White
if(!require(rgdal)) install.packages("rgdal")
setwd("data/shp_global110")  # set working directory
getwd() # print working directory
## use readOGR(dsn, layer) to read shapefile
land <- readOGR(".", "110m_land")   # "." represents current working directory
admin <- readOGR(".", "110m_admin_0_countries")
plot(land)
class(land)
#str(land)
# access some information about this object
proj <- proj4string(land)	# get the projection / coordinate reference system
proj
bbox(land)	# bounding box
land@bbox
xy <- coordinates(land)	# coordinates
summary(xy)
points(xy, pch=16,col="red")	# These are only the centre coordinates of the polygons!
# access the attribute table of a vector dataset with @data
data.df <- land@data
library(knitr)
kable(head(data.df,10))
summary(data.df)
setwd("data/shp_global110")
getwd()
files <- list.files(pattern=".shp")
files	# filenames of the files to be read
world <- readOGR(".","110m_land")
plot(world,col="grey",border="blue",bg = "lightblue")
plot(admin,add=TRUE)
lakes <- readOGR(".","110m_lakes")
plot(lakes,add=TRUE,col = "blue")
ocean <- readOGR(".","110m_ocean")
plot(ocean,add=TRUE,col = "lightblue")
setwd("output")
getwd()
setwd("output")
getwd()
library(rgdal)
writeOGR(land,dsn = ".",layer = "land",driver="ESRI Shapefile",overwrite_layer = TRUE)
shp <- readOGR(dsn = ".", layer = "land")
plot(shp)
bbox(shp)
proj4string(shp)
xy <- coordinates(shp)
df <- shp@data
names(df)
names(xy)
slotNames(shp)
plot(shp)
points(xy, pch=16,col="red")
library(rgdal)
setwd("data/shp_global110")
folder <- getwd()
shp <- readOGR(dsn = folder,layer = "continent")
getwd()
library(rgdal)
setwd("data/shp_global110")
folder <- getwd()
shp <- readOGR(dsn = folder,layer = "continent")
library(rgdal)
setwd("data/shp_global110")
folder <- "data/shp_global110"
shp <- readOGR(dsn = folder,layer = "continent")
getwd()
library(rgdal)
setwd("data/shp_global110")
folder <- getwd()
shp <- readOGR(dsn = folder,layer = "continent")
plot(shp,col="grey")
plot(shp,lwd=2,add=TRUE)
df <- shp@data
library(knitr)
kable(head(df,10))
sel <- df$CONTINENT == "North America"
plot(shp[sel,])
setwd("data/gimms_ndvi/")
getwd()
if(!require(ncdf4)) install.packages("ncdf4")
library(ncdf4)
library(raster)
ndvi <- raster("GIMMS.NDVI.360.720.2000.2002.30days.nc")
ndvi
plot(ndvi)
str(ndvi)
nrow(ndvi)
ncol(ndvi)
ncell(ndvi)
extent(ndvi)
bbox(ndvi)
res(ndvi)
projection(ndvi)
setwd("data/gimms_ndvi/")
getwd()
ndvi.rb <- brick("GIMMS.NDVI.360.720.2000.2002.30days.nc")
ndvi.rb
ndvi2000 <- ndvi.rb[[1:12]] # select bands as a new raster
plot(ndvi.rb)      # plot all bands
plot(ndvi.rb,6)    # plot a single band
plot(ndvi.rb,1:12) # plot selected bands
plot(ndvi.rb,1)
#values <- click(ndvi.rb, n=1, xy=TRUE)
#values <- click(ndvi.rb, n=1, xy=FALSE)
values <- ndvi.rb[50,50]
plot(as.vector(values), type="b")
spent <- c(120,68,35,60,100,91,44,71,89,113)
income <- c(65,35,30,44,80,77,32,39,44,77)
m <- lm(spent~income)
summary(m)
fitted(m)
resid(m)
plot(m)
library(arcgisbinding)
arc.check_product()
enrich_df <- arc.open(path = 'data/San_Francisco_Crimes_Enrich_Subset.shp')
enrich_df <- arc.open(path = 'data/crime/San_Francisco_Crimes_Enrich_Subset.shp')
enrich_select_df <- arc.select(object = enrich_df, fields = c('FID', 'SUM_VALUE', 'TOTPOP00', 'MEDHINC_CY', 'RENTER_CY', 'MEDVAL_FY', 'N13_BUS', 'N37_BUS', 'NLCDfrstPt'))
summary(enrich_df)
enrich_select_df <- arc.select(object = enrich_df, fields = c('FID', 'SUM_VALUE', 'TOTPOP10', 'MEDHINC_CY', 'RENTER_CY', 'MEDVAL_CY', 'N13_BUS', 'N37_BUS', 'NLCDfrstPt'))
library(sp)
enrich_spdf <- arc.data2sp(enrich_select_df)
col_names <- c("OBJECTID", "Crime_Counts",
"Population", "Med_HomeIncome",
"Renter_Count", "Med_HomeValue", "Grocery",
"Restaurant", "Pct_Forest")
colnames(enrich_spdf@data) <- col_names
head(enrich_spdf@data)
library(spdep)
n <- enrich_spdf@data$Crime_Counts
x <- enrich_spdf@data$Population
EB <- EBest (n, x)
p <- EB$raw
b <- attr(EB, "parameters")$b
a <- attr(EB, "parameters")$a
v <- a + (b/x)
v[v < 0] <- b/x
z <- (p - b)/sqrt(v)
enrich_spdf@data$EB_Rate <- z
arcgis_df <- arc.sp2data(enrich_spdf)
arc.write('output/San_Francisco_Crime_Rates.shp', arcgis_df)
rate_df <- arc.open('output/San_Francisco_Crime_Rates.shp')
rate_select_df <- arc.select(rate_df, fields = c("OBJECTID_1", "Crime_Coun", "Population", "Med_HomeIn", "Renter_Cou", "Med_HomeVa", "Grocery", "Restaurant", "Pct_Forest", "EB_Rate"))
rate_spdf <- arc.data2sp(rate_select_df)
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat) {
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
#
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat) {
cormat[lower.tri(cormat)] <- NA
return(cormat)
}
#
reorder_cormat <- function(cormat) {
# Use correlation between variables as distance
dd <- as.dist((1-cormat) / 2)
hc <- hclust(dd)
cormat <- cormat [hc$order, hc$order]
}
library (reshape2)
# install.packages("ggplot2")
library (ggplot2)
# install.packages("ggmap")
library (ggmap)
corr_sub <- rate_spdf@data [ c ("Grocery", "Restaurant", "Pct_Forest", "Med_HomeIn", "Renter_Cou", "Med_HomeVa", "EB_Rate")]
cormax <- round (cor(corr_sub), 2)
upper_tri <- get_upper_tri (cormax)
melted_cormax <- melt (upper_tri, na.rm = TRUE)
cormax <- reorder_cormat (cormax)
upper_tri <- get_upper_tri (cormax)
melted_cormax <- melt (upper_tri, na.rm = TRUE)
ggheatmap <- ggplot (melted_cormax, aes (Var2, Var1, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2 (low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1,1), space = "Lab", name = "Pearson\nCorrelation") +
theme_minimal() + # minimal theme
theme (axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
coord_fixed()
print (ggheatmap)
ggheatmap +
geom_text (aes (Var2, Var1, label = value), color = "black", size = 4) +
theme (
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
legend.justification = c (1, 0),
legend.position = c (0.6, 0.7),
legend.direction = "horizontal") +
guides (fill = guide_colorbar (barwidth = 7, barheight = 1, title.position = "top", title.hjust = 0.5))
rnorm(n = 10)
rnorm(n = 100)
rnorm()
rnorm(n = 10,mean = 5,sd = 3)
rnorm(10,5,3)
set.seed(1)
rnorm(10,5,3)
rnorm(10,5,3)
rnorm(10,5,3)
set.seed(10)
rnorm(10,5,3)
set.seed(10)
rnorm(10,5,3)
rnorm(10,sd = 3,mean = 5)
x <- rnorm(20)
rnorm(20)
y <- rnorm(20)
cor(x)
cor(x,y)
cor.test(x,y)
url <- "D:Dropbox\GitHub\sysu-workshop\R\projects\data\ExamAnxiety.csv"
url <- "D:Dropbox\GitHub\sysu-workshop\R\projects\data\ExamAnxiety.csv"
df <- read.csv("data/ExamAnxiety.csv",header = TRUE)
View(df)
df <- read.csv("data/ExamAnxiety.csv",header = FALSE)
View(df)
df <- read.csv("data/ExamAnxiety.csv",header = TRUE)
View(df)
plot(df)
x <- seq(from=0,to = 1,length.out = 100)
y <- x + rnorm(100)
plot(x,y)
x <- seq(from=0,to = 1,length.out = 10000)
y <- x + rnorm(10000)
plot(x,y)
plot(x)
y <- x + rnorm(10000)
plot(x,y)
x <- seq(from=0,to = 1,length.out = 1000)
y <- x + rnorm(1000)
plot(x,y)
library("boot", lib.loc="C:/Program Files/R/R-3.4.0/library")
detach("package:boot", unload=TRUE)
mtcars
df <- mtcars
View(df)
cor(df)
plot(df)
df$mpg
x <- df$mpg
sub_df <- df[,1:4]
View(sub_df)
sub_df <- df[1:10,1:4]
View(sub_df)
sub_df <- df[1:10,c(1,5,7,8)]
View(sub_df)
sub_df <- df[,c(1,5,7,8)]
plot(sub_df)
cor(sub_df)
plot(df$hp,df$qsec)
abline(lm(df$qsec ~ df$hp))
mpg
mpg <- df$mpg
wt <- df$wt
plot(wt, mpg)
examData <- read.csv("data/ExamAnxiety.csv",header = TRUE)
cor(examData, use = "complete.obs", method = "pearson")
cor.test(examData$Exam, examData$Anxiety, method = "pearson")
df <- read.csv("data/AlbumSales1.csv",header = TRUE)
plot(df)
m <- lm(df$sales ~ df$adverts)
df <- read.csv("data/AlbumSales1.csv",header = TRUE)
plot(df)
m <- lm(df$sales ~ df$adverts)
m
View(df)
m <- lm(sales ~ adverts)
View(df)
m <- lm(sales ~ adverts, data = df)
summary(m)
m
summary(m)
df <- cars
View(df)
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(sales ~ adverts, data = df)
df <- read.csv("data/AlbumSales1.csv",header = TRUE)
m <- lm(sales ~ adverts, data = df)
summary(m)
abline(m,col="red",lwd=2)
abline(m,col="red",lwd=2)
df <- cars
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
df <- cars
plot(df)
x <- cars$speed
y <- cars$dist
plot(y ~ x)
m <- lm(y~x)
summary(m)
abline(m,col="red",lwd=2)
abline(m,col="blue",lwd=2)
abline(m,col="blue",lwd=5)
fitted(x)
fitted(m)
residuals(m)
segments(x,fitted(m),x,y,col="blue",lty = "dashed")
anova(m)
coefficients(m)
fitted(m)
residuals(m)
resid(m)
summary(m)
url <- "data/AlbumSales2.csv"
df <- read.csv(url,header = TRUE)
library(knitr)
kable(head(df,10))
m <- lm(sales ~ adverts + airplay + attract, data = df)
## m <- lm(sales ~ ., data = df)
summary(m)
anova(m)
coefficients(m)
coef(m)
a <- round(coef(m)[1],2)
b1 <- round(coef(m)[2],2)
b2 <- round(coef(m)[3],2)
b3 <- round(coef(m)[4],2)
url <- "data/AlbumSales2.csv"
df <- read.csv(url,header = TRUE)
m <- lm(sales ~ adverts + airplay + attract + 0, data = df)
summary(m)
m <- lm(sales ~ adverts + airplay + attract + airplay * attract, data = df)
summary(m)
m <- lm(sales ~ adverts + airplay + attract , data = df)
summary(m)
m <- lm(sales ~ adverts + airplay + attract + 0, data = df)
summary(m)
